{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/liwenliang/anaconda3/envs/rob/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd \n",
    "import gc\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm\n",
    "from sklearn.metrics import precision_score,recall_score,roc_auc_score,classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Classification\n",
    "user_embedding*item_embedding->score(x)\n",
    "->task(y)\n",
    "->lightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scores</th>\n",
       "      <th>scores.1</th>\n",
       "      <th>scores.2</th>\n",
       "      <th>scores.3</th>\n",
       "      <th>scores.4</th>\n",
       "      <th>scores.5</th>\n",
       "      <th>scores.6</th>\n",
       "      <th>scores.7</th>\n",
       "      <th>scores.8</th>\n",
       "      <th>group_scores</th>\n",
       "      <th>...</th>\n",
       "      <th>interval</th>\n",
       "      <th>price</th>\n",
       "      <th>price.1</th>\n",
       "      <th>price.2</th>\n",
       "      <th>price.3</th>\n",
       "      <th>price.4</th>\n",
       "      <th>price.5</th>\n",
       "      <th>price.6</th>\n",
       "      <th>price.7</th>\n",
       "      <th>price.8</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.334250</td>\n",
       "      <td>0.312646</td>\n",
       "      <td>0.310058</td>\n",
       "      <td>0.317037</td>\n",
       "      <td>0.277637</td>\n",
       "      <td>0.314117</td>\n",
       "      <td>0.325306</td>\n",
       "      <td>0.340136</td>\n",
       "      <td>0.371542</td>\n",
       "      <td>0.318985</td>\n",
       "      <td>...</td>\n",
       "      <td>0.80</td>\n",
       "      <td>2954.0</td>\n",
       "      <td>1978.0</td>\n",
       "      <td>295.0</td>\n",
       "      <td>559.0</td>\n",
       "      <td>1793.0</td>\n",
       "      <td>1429.0</td>\n",
       "      <td>2199.0</td>\n",
       "      <td>690.0</td>\n",
       "      <td>3777.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.405298</td>\n",
       "      <td>0.322350</td>\n",
       "      <td>0.436186</td>\n",
       "      <td>0.375337</td>\n",
       "      <td>0.176343</td>\n",
       "      <td>0.489126</td>\n",
       "      <td>0.577481</td>\n",
       "      <td>0.312774</td>\n",
       "      <td>0.486421</td>\n",
       "      <td>0.387945</td>\n",
       "      <td>...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2954.0</td>\n",
       "      <td>1486.0</td>\n",
       "      <td>1271.0</td>\n",
       "      <td>1787.0</td>\n",
       "      <td>1793.0</td>\n",
       "      <td>1430.0</td>\n",
       "      <td>11997.0</td>\n",
       "      <td>497.0</td>\n",
       "      <td>7000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.356495</td>\n",
       "      <td>0.343906</td>\n",
       "      <td>0.362385</td>\n",
       "      <td>0.349160</td>\n",
       "      <td>0.258404</td>\n",
       "      <td>0.350972</td>\n",
       "      <td>0.232758</td>\n",
       "      <td>0.494536</td>\n",
       "      <td>0.368001</td>\n",
       "      <td>0.354262</td>\n",
       "      <td>...</td>\n",
       "      <td>0.65</td>\n",
       "      <td>637.0</td>\n",
       "      <td>1486.0</td>\n",
       "      <td>295.0</td>\n",
       "      <td>5208.0</td>\n",
       "      <td>1780.0</td>\n",
       "      <td>4578.0</td>\n",
       "      <td>1768.0</td>\n",
       "      <td>1756.0</td>\n",
       "      <td>5558.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.332843</td>\n",
       "      <td>0.328229</td>\n",
       "      <td>0.307702</td>\n",
       "      <td>0.279055</td>\n",
       "      <td>0.376070</td>\n",
       "      <td>0.364445</td>\n",
       "      <td>0.334881</td>\n",
       "      <td>0.465579</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0.322925</td>\n",
       "      <td>...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>593.0</td>\n",
       "      <td>478.0</td>\n",
       "      <td>2954.0</td>\n",
       "      <td>239.0</td>\n",
       "      <td>1488.0</td>\n",
       "      <td>1432.0</td>\n",
       "      <td>1387.0</td>\n",
       "      <td>6037.0</td>\n",
       "      <td>7000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.417497</td>\n",
       "      <td>0.405888</td>\n",
       "      <td>0.356196</td>\n",
       "      <td>0.338698</td>\n",
       "      <td>0.281830</td>\n",
       "      <td>0.410781</td>\n",
       "      <td>0.357581</td>\n",
       "      <td>0.546216</td>\n",
       "      <td>0.378840</td>\n",
       "      <td>0.393194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>2954.0</td>\n",
       "      <td>478.0</td>\n",
       "      <td>279.0</td>\n",
       "      <td>2770.0</td>\n",
       "      <td>1787.0</td>\n",
       "      <td>1959.0</td>\n",
       "      <td>7000.0</td>\n",
       "      <td>1065.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260083</th>\n",
       "      <td>0.373168</td>\n",
       "      <td>0.363249</td>\n",
       "      <td>0.368822</td>\n",
       "      <td>0.308188</td>\n",
       "      <td>0.287073</td>\n",
       "      <td>0.259102</td>\n",
       "      <td>0.445450</td>\n",
       "      <td>0.303088</td>\n",
       "      <td>0.347769</td>\n",
       "      <td>0.368413</td>\n",
       "      <td>...</td>\n",
       "      <td>0.85</td>\n",
       "      <td>1207.0</td>\n",
       "      <td>618.0</td>\n",
       "      <td>946.0</td>\n",
       "      <td>1117.0</td>\n",
       "      <td>1785.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>10594.0</td>\n",
       "      <td>4079.0</td>\n",
       "      <td>2383.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260084</th>\n",
       "      <td>0.436682</td>\n",
       "      <td>0.295297</td>\n",
       "      <td>0.309889</td>\n",
       "      <td>0.349857</td>\n",
       "      <td>0.352108</td>\n",
       "      <td>0.311665</td>\n",
       "      <td>0.321082</td>\n",
       "      <td>0.311732</td>\n",
       "      <td>0.454284</td>\n",
       "      <td>0.347289</td>\n",
       "      <td>...</td>\n",
       "      <td>0.65</td>\n",
       "      <td>1222.0</td>\n",
       "      <td>475.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>2492.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>1793.0</td>\n",
       "      <td>943.0</td>\n",
       "      <td>1788.0</td>\n",
       "      <td>7000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260085</th>\n",
       "      <td>0.347315</td>\n",
       "      <td>0.435804</td>\n",
       "      <td>0.332577</td>\n",
       "      <td>0.399524</td>\n",
       "      <td>0.317818</td>\n",
       "      <td>0.313250</td>\n",
       "      <td>0.409925</td>\n",
       "      <td>0.455442</td>\n",
       "      <td>0.403814</td>\n",
       "      <td>0.371899</td>\n",
       "      <td>...</td>\n",
       "      <td>0.65</td>\n",
       "      <td>295.0</td>\n",
       "      <td>693.0</td>\n",
       "      <td>593.0</td>\n",
       "      <td>897.0</td>\n",
       "      <td>349.0</td>\n",
       "      <td>2769.0</td>\n",
       "      <td>6037.0</td>\n",
       "      <td>3500.0</td>\n",
       "      <td>3777.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260086</th>\n",
       "      <td>0.401205</td>\n",
       "      <td>0.374106</td>\n",
       "      <td>0.363304</td>\n",
       "      <td>0.369179</td>\n",
       "      <td>0.360475</td>\n",
       "      <td>0.357022</td>\n",
       "      <td>0.487978</td>\n",
       "      <td>0.394191</td>\n",
       "      <td>0.404322</td>\n",
       "      <td>0.379538</td>\n",
       "      <td>...</td>\n",
       "      <td>0.65</td>\n",
       "      <td>832.0</td>\n",
       "      <td>1486.0</td>\n",
       "      <td>637.0</td>\n",
       "      <td>1780.0</td>\n",
       "      <td>418.0</td>\n",
       "      <td>653.0</td>\n",
       "      <td>7000.0</td>\n",
       "      <td>3086.0</td>\n",
       "      <td>1181.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260087</th>\n",
       "      <td>0.374106</td>\n",
       "      <td>0.377405</td>\n",
       "      <td>0.357605</td>\n",
       "      <td>0.439347</td>\n",
       "      <td>0.336109</td>\n",
       "      <td>0.381732</td>\n",
       "      <td>0.451648</td>\n",
       "      <td>0.369659</td>\n",
       "      <td>0.487978</td>\n",
       "      <td>0.369706</td>\n",
       "      <td>...</td>\n",
       "      <td>0.65</td>\n",
       "      <td>1486.0</td>\n",
       "      <td>636.0</td>\n",
       "      <td>986.0</td>\n",
       "      <td>2240.0</td>\n",
       "      <td>1092.0</td>\n",
       "      <td>1400.0</td>\n",
       "      <td>2383.0</td>\n",
       "      <td>1724.0</td>\n",
       "      <td>7000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>260085 rows × 76 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           scores  scores.1  scores.2  scores.3  scores.4  scores.5  scores.6  \\\n",
       "user_id                                                                         \n",
       "1        0.334250  0.312646  0.310058  0.317037  0.277637  0.314117  0.325306   \n",
       "2        0.405298  0.322350  0.436186  0.375337  0.176343  0.489126  0.577481   \n",
       "3        0.356495  0.343906  0.362385  0.349160  0.258404  0.350972  0.232758   \n",
       "4        0.332843  0.328229  0.307702  0.279055  0.376070  0.364445  0.334881   \n",
       "5        0.417497  0.405888  0.356196  0.338698  0.281830  0.410781  0.357581   \n",
       "...           ...       ...       ...       ...       ...       ...       ...   \n",
       "260083   0.373168  0.363249  0.368822  0.308188  0.287073  0.259102  0.445450   \n",
       "260084   0.436682  0.295297  0.309889  0.349857  0.352108  0.311665  0.321082   \n",
       "260085   0.347315  0.435804  0.332577  0.399524  0.317818  0.313250  0.409925   \n",
       "260086   0.401205  0.374106  0.363304  0.369179  0.360475  0.357022  0.487978   \n",
       "260087   0.374106  0.377405  0.357605  0.439347  0.336109  0.381732  0.451648   \n",
       "\n",
       "         scores.7  scores.8  group_scores  ...  interval   price  price.1  \\\n",
       "user_id                                    ...                              \n",
       "1        0.340136  0.371542      0.318985  ...      0.80  2954.0   1978.0   \n",
       "2        0.312774  0.486421      0.387945  ...      0.75  2954.0   1486.0   \n",
       "3        0.494536  0.368001      0.354262  ...      0.65   637.0   1486.0   \n",
       "4        0.465579  0.397959      0.322925  ...      0.75   593.0    478.0   \n",
       "5        0.546216  0.378840      0.393194  ...      0.70  1479.0   2954.0   \n",
       "...           ...       ...           ...  ...       ...     ...      ...   \n",
       "260083   0.303088  0.347769      0.368413  ...      0.85  1207.0    618.0   \n",
       "260084   0.311732  0.454284      0.347289  ...      0.65  1222.0    475.0   \n",
       "260085   0.455442  0.403814      0.371899  ...      0.65   295.0    693.0   \n",
       "260086   0.394191  0.404322      0.379538  ...      0.65   832.0   1486.0   \n",
       "260087   0.369659  0.487978      0.369706  ...      0.65  1486.0    636.0   \n",
       "\n",
       "         price.2  price.3  price.4  price.5  price.6  price.7  price.8  \n",
       "user_id                                                                 \n",
       "1          295.0    559.0   1793.0   1429.0   2199.0    690.0   3777.0  \n",
       "2         1271.0   1787.0   1793.0   1430.0  11997.0    497.0   7000.0  \n",
       "3          295.0   5208.0   1780.0   4578.0   1768.0   1756.0   5558.0  \n",
       "4         2954.0    239.0   1488.0   1432.0   1387.0   6037.0   7000.0  \n",
       "5          478.0    279.0   2770.0   1787.0   1959.0   7000.0   1065.0  \n",
       "...          ...      ...      ...      ...      ...      ...      ...  \n",
       "260083     946.0   1117.0   1785.0    676.0  10594.0   4079.0   2383.0  \n",
       "260084     199.0   2492.0    558.0   1793.0    943.0   1788.0   7000.0  \n",
       "260085     593.0    897.0    349.0   2769.0   6037.0   3500.0   3777.0  \n",
       "260086     637.0   1780.0    418.0    653.0   7000.0   3086.0   1181.0  \n",
       "260087     986.0   2240.0   1092.0   1400.0   2383.0   1724.0   7000.0  \n",
       "\n",
       "[260085 rows x 76 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_i = pd.read_csv('./datasets/data.csv')\n",
    "events = pd.read_csv('./datasets/event.csv')\n",
    "user_id = events['user_id']\n",
    "data_i = data_i.set_index(user_id)\n",
    "data_i = data_i.drop(events[events['labels']=='1,1,0,0,1,0,0,0,1'].index,axis = 0)\n",
    "data_i = data_i.drop(events[events['labels']=='0,1,0,1,0,0,1,0,0'].index,axis = 0)\n",
    "# data_i = data_i.drop(bb[bb.iloc[:,6]!=54240].index,axis = 0)\n",
    "y = events['labels'].drop(events[events['labels']=='1,1,0,0,1,0,0,0,1'].index,axis = 0)\n",
    "y = y.drop(events[events['labels']=='0,1,0,1,0,0,1,0,0'].index,axis = 0)\n",
    "# y = y.drop(bb[bb.iloc[:,6]!=54240].index,axis = 0)\n",
    "data_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scores</th>\n",
       "      <th>scores.1</th>\n",
       "      <th>scores.2</th>\n",
       "      <th>scores.3</th>\n",
       "      <th>scores.4</th>\n",
       "      <th>scores.5</th>\n",
       "      <th>scores.6</th>\n",
       "      <th>scores.7</th>\n",
       "      <th>scores.8</th>\n",
       "      <th>group_scores</th>\n",
       "      <th>...</th>\n",
       "      <th>interval</th>\n",
       "      <th>price</th>\n",
       "      <th>price.1</th>\n",
       "      <th>price.2</th>\n",
       "      <th>price.3</th>\n",
       "      <th>price.4</th>\n",
       "      <th>price.5</th>\n",
       "      <th>price.6</th>\n",
       "      <th>price.7</th>\n",
       "      <th>price.8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.361060</td>\n",
       "      <td>0.319881</td>\n",
       "      <td>0.295002</td>\n",
       "      <td>0.303006</td>\n",
       "      <td>0.344006</td>\n",
       "      <td>0.323102</td>\n",
       "      <td>0.399915</td>\n",
       "      <td>0.353739</td>\n",
       "      <td>0.412664</td>\n",
       "      <td>0.325315</td>\n",
       "      <td>...</td>\n",
       "      <td>0.85</td>\n",
       "      <td>757.0</td>\n",
       "      <td>593.0</td>\n",
       "      <td>1207.0</td>\n",
       "      <td>898.0</td>\n",
       "      <td>359.0</td>\n",
       "      <td>358.0</td>\n",
       "      <td>3777.0</td>\n",
       "      <td>1188.0</td>\n",
       "      <td>7000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.365978</td>\n",
       "      <td>0.430513</td>\n",
       "      <td>0.418576</td>\n",
       "      <td>0.423834</td>\n",
       "      <td>0.290246</td>\n",
       "      <td>0.408647</td>\n",
       "      <td>0.329504</td>\n",
       "      <td>0.369062</td>\n",
       "      <td>0.480752</td>\n",
       "      <td>0.405022</td>\n",
       "      <td>...</td>\n",
       "      <td>0.85</td>\n",
       "      <td>637.0</td>\n",
       "      <td>1207.0</td>\n",
       "      <td>946.0</td>\n",
       "      <td>1557.0</td>\n",
       "      <td>2770.0</td>\n",
       "      <td>2181.0</td>\n",
       "      <td>1181.0</td>\n",
       "      <td>2199.0</td>\n",
       "      <td>3777.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.428479</td>\n",
       "      <td>0.464028</td>\n",
       "      <td>0.278901</td>\n",
       "      <td>0.409794</td>\n",
       "      <td>0.336164</td>\n",
       "      <td>0.323324</td>\n",
       "      <td>0.342695</td>\n",
       "      <td>0.334072</td>\n",
       "      <td>0.362839</td>\n",
       "      <td>0.390469</td>\n",
       "      <td>...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1207.0</td>\n",
       "      <td>693.0</td>\n",
       "      <td>475.0</td>\n",
       "      <td>1400.0</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>2492.0</td>\n",
       "      <td>4079.0</td>\n",
       "      <td>2513.0</td>\n",
       "      <td>497.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.317010</td>\n",
       "      <td>0.337044</td>\n",
       "      <td>0.336006</td>\n",
       "      <td>0.324239</td>\n",
       "      <td>0.379250</td>\n",
       "      <td>0.316856</td>\n",
       "      <td>0.333559</td>\n",
       "      <td>0.391231</td>\n",
       "      <td>0.284750</td>\n",
       "      <td>0.330020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1207.0</td>\n",
       "      <td>636.0</td>\n",
       "      <td>693.0</td>\n",
       "      <td>559.0</td>\n",
       "      <td>3873.0</td>\n",
       "      <td>2148.0</td>\n",
       "      <td>2199.0</td>\n",
       "      <td>3500.0</td>\n",
       "      <td>2235.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.289547</td>\n",
       "      <td>0.344884</td>\n",
       "      <td>0.314824</td>\n",
       "      <td>0.337340</td>\n",
       "      <td>0.325776</td>\n",
       "      <td>0.236394</td>\n",
       "      <td>0.336476</td>\n",
       "      <td>0.299571</td>\n",
       "      <td>0.375464</td>\n",
       "      <td>0.316419</td>\n",
       "      <td>...</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1486.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>295.0</td>\n",
       "      <td>646.0</td>\n",
       "      <td>1400.0</td>\n",
       "      <td>1793.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>1387.0</td>\n",
       "      <td>6041.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206249</th>\n",
       "      <td>-0.001540</td>\n",
       "      <td>-0.010733</td>\n",
       "      <td>-0.007529</td>\n",
       "      <td>-0.002096</td>\n",
       "      <td>-0.001996</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>-0.006069</td>\n",
       "      <td>0.002672</td>\n",
       "      <td>-0.006601</td>\n",
       "      <td>...</td>\n",
       "      <td>0.60</td>\n",
       "      <td>295.0</td>\n",
       "      <td>589.0</td>\n",
       "      <td>946.0</td>\n",
       "      <td>836.0</td>\n",
       "      <td>448.0</td>\n",
       "      <td>1117.0</td>\n",
       "      <td>3777.0</td>\n",
       "      <td>745.0</td>\n",
       "      <td>3500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206250</th>\n",
       "      <td>0.408904</td>\n",
       "      <td>0.365829</td>\n",
       "      <td>0.362110</td>\n",
       "      <td>0.358949</td>\n",
       "      <td>0.377627</td>\n",
       "      <td>0.324649</td>\n",
       "      <td>0.510981</td>\n",
       "      <td>0.410309</td>\n",
       "      <td>0.304880</td>\n",
       "      <td>0.378948</td>\n",
       "      <td>...</td>\n",
       "      <td>0.65</td>\n",
       "      <td>593.0</td>\n",
       "      <td>596.0</td>\n",
       "      <td>589.0</td>\n",
       "      <td>803.0</td>\n",
       "      <td>1195.0</td>\n",
       "      <td>5208.0</td>\n",
       "      <td>11768.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>2389.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206251</th>\n",
       "      <td>-0.006049</td>\n",
       "      <td>0.006241</td>\n",
       "      <td>0.003537</td>\n",
       "      <td>-0.001775</td>\n",
       "      <td>0.003555</td>\n",
       "      <td>0.000552</td>\n",
       "      <td>0.002672</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>0.002841</td>\n",
       "      <td>0.001243</td>\n",
       "      <td>...</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>478.0</td>\n",
       "      <td>1486.0</td>\n",
       "      <td>3338.0</td>\n",
       "      <td>559.0</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>3500.0</td>\n",
       "      <td>4079.0</td>\n",
       "      <td>497.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206252</th>\n",
       "      <td>0.282106</td>\n",
       "      <td>0.369575</td>\n",
       "      <td>0.603263</td>\n",
       "      <td>0.207410</td>\n",
       "      <td>0.362853</td>\n",
       "      <td>0.267989</td>\n",
       "      <td>0.252864</td>\n",
       "      <td>0.398873</td>\n",
       "      <td>0.569444</td>\n",
       "      <td>0.418315</td>\n",
       "      <td>...</td>\n",
       "      <td>0.65</td>\n",
       "      <td>1962.0</td>\n",
       "      <td>876.0</td>\n",
       "      <td>2954.0</td>\n",
       "      <td>279.0</td>\n",
       "      <td>896.0</td>\n",
       "      <td>359.0</td>\n",
       "      <td>8524.0</td>\n",
       "      <td>3777.0</td>\n",
       "      <td>5396.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206253</th>\n",
       "      <td>0.523900</td>\n",
       "      <td>0.254323</td>\n",
       "      <td>0.270652</td>\n",
       "      <td>0.364188</td>\n",
       "      <td>0.403831</td>\n",
       "      <td>0.238451</td>\n",
       "      <td>0.366069</td>\n",
       "      <td>0.465630</td>\n",
       "      <td>0.307833</td>\n",
       "      <td>0.349625</td>\n",
       "      <td>...</td>\n",
       "      <td>0.65</td>\n",
       "      <td>1315.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>299.0</td>\n",
       "      <td>803.0</td>\n",
       "      <td>1785.0</td>\n",
       "      <td>2770.0</td>\n",
       "      <td>16621.0</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>2199.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>206254 rows × 76 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          scores  scores.1  scores.2  scores.3  scores.4  scores.5  scores.6  \\\n",
       "0       0.361060  0.319881  0.295002  0.303006  0.344006  0.323102  0.399915   \n",
       "1       0.365978  0.430513  0.418576  0.423834  0.290246  0.408647  0.329504   \n",
       "2       0.428479  0.464028  0.278901  0.409794  0.336164  0.323324  0.342695   \n",
       "3       0.317010  0.337044  0.336006  0.324239  0.379250  0.316856  0.333559   \n",
       "4       0.289547  0.344884  0.314824  0.337340  0.325776  0.236394  0.336476   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "206249 -0.001540 -0.010733 -0.007529 -0.002096 -0.001996 -0.000172  0.000051   \n",
       "206250  0.408904  0.365829  0.362110  0.358949  0.377627  0.324649  0.510981   \n",
       "206251 -0.006049  0.006241  0.003537 -0.001775  0.003555  0.000552  0.002672   \n",
       "206252  0.282106  0.369575  0.603263  0.207410  0.362853  0.267989  0.252864   \n",
       "206253  0.523900  0.254323  0.270652  0.364188  0.403831  0.238451  0.366069   \n",
       "\n",
       "        scores.7  scores.8  group_scores  ...  interval   price  price.1  \\\n",
       "0       0.353739  0.412664      0.325315  ...      0.85   757.0    593.0   \n",
       "1       0.369062  0.480752      0.405022  ...      0.85   637.0   1207.0   \n",
       "2       0.334072  0.362839      0.390469  ...      0.75  1207.0    693.0   \n",
       "3       0.391231  0.284750      0.330020  ...      0.70  1207.0    636.0   \n",
       "4       0.299571  0.375464      0.316419  ...      0.70  1486.0    199.0   \n",
       "...          ...       ...           ...  ...       ...     ...      ...   \n",
       "206249 -0.006069  0.002672     -0.006601  ...      0.60   295.0    589.0   \n",
       "206250  0.410309  0.304880      0.378948  ...      0.65   593.0    596.0   \n",
       "206251  0.000217  0.002841      0.001243  ...      0.60  1479.0    478.0   \n",
       "206252  0.398873  0.569444      0.418315  ...      0.65  1962.0    876.0   \n",
       "206253  0.465630  0.307833      0.349625  ...      0.65  1315.0    199.0   \n",
       "\n",
       "        price.2  price.3  price.4  price.5  price.6  price.7  price.8  \n",
       "0        1207.0    898.0    359.0    358.0   3777.0   1188.0   7000.0  \n",
       "1         946.0   1557.0   2770.0   2181.0   1181.0   2199.0   3777.0  \n",
       "2         475.0   1400.0   1440.0   2492.0   4079.0   2513.0    497.0  \n",
       "3         693.0    559.0   3873.0   2148.0   2199.0   3500.0   2235.0  \n",
       "4         295.0    646.0   1400.0   1793.0    549.0   1387.0   6041.0  \n",
       "...         ...      ...      ...      ...      ...      ...      ...  \n",
       "206249    946.0    836.0    448.0   1117.0   3777.0    745.0   3500.0  \n",
       "206250    589.0    803.0   1195.0   5208.0  11768.0   2000.0   2389.0  \n",
       "206251   1486.0   3338.0    559.0   1440.0   3500.0   4079.0    497.0  \n",
       "206252   2954.0    279.0    896.0    359.0   8524.0   3777.0   5396.0  \n",
       "206253    299.0    803.0   1785.0   2770.0  16621.0   8000.0   2199.0  \n",
       "\n",
       "[206254 rows x 76 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_i_v = pd.read_csv('./datasets/data_v.csv')\n",
    "x_valid = data_i_v\n",
    "x_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn import metrics\n",
    "# kf = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 0)\n",
    "# # kf = KFold(n_splits = 5, shuffle = True, random_state = 0)\n",
    "# # y_pred = np.zeros(len(x_test))\n",
    "\n",
    "# for fold,(train_index,val_index) in enumerate(kf.split(X_train,Y_train)):\n",
    "#     x_train,x_val = X_train.iloc[train_index],X_train.iloc[val_index]\n",
    "# #     Y_train = Y_train.str.split(',')\n",
    "#     y_train,y_val = Y_train.iloc[train_index],Y_train.iloc[val_index]\n",
    "#     train_set = lgb.Dataset(x_train,y_train)\n",
    "#     val_set = lgb.Dataset(x_val,y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = lightgbm.LGBMClassifier(boosting_type='gbdt', num_leaves=256,reg_alpha=0.0,reg_lambda=1,\n",
    "max_depth=8, n_estimators=80,objective='multiclassova' ,num_class = 22,\n",
    "learning_rate=0.08,random_state=20,n_jobs=4)#,class_weight = weights)#,lambda_l1 = 0.3,lambda_l2 = 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's multi_error: 0.764005\tvalid_0's multi_logloss: 2.50027\n",
      "[2]\tvalid_0's multi_error: 0.701872\tvalid_0's multi_logloss: 2.40255\n",
      "[3]\tvalid_0's multi_error: 0.649429\tvalid_0's multi_logloss: 2.32921\n",
      "[4]\tvalid_0's multi_error: 0.6219\tvalid_0's multi_logloss: 2.27037\n",
      "[5]\tvalid_0's multi_error: 0.604483\tvalid_0's multi_logloss: 2.22172\n",
      "[6]\tvalid_0's multi_error: 0.59637\tvalid_0's multi_logloss: 2.18152\n",
      "[7]\tvalid_0's multi_error: 0.590603\tvalid_0's multi_logloss: 2.14629\n",
      "[8]\tvalid_0's multi_error: 0.586297\tvalid_0's multi_logloss: 2.1157\n",
      "[9]\tvalid_0's multi_error: 0.581952\tvalid_0's multi_logloss: 2.08954\n",
      "[10]\tvalid_0's multi_error: 0.578338\tvalid_0's multi_logloss: 2.06634\n",
      "[11]\tvalid_0's multi_error: 0.575801\tvalid_0's multi_logloss: 2.04587\n",
      "[12]\tvalid_0's multi_error: 0.574263\tvalid_0's multi_logloss: 2.02825\n",
      "[13]\tvalid_0's multi_error: 0.573263\tvalid_0's multi_logloss: 2.01263\n",
      "[14]\tvalid_0's multi_error: 0.571802\tvalid_0's multi_logloss: 1.99864\n",
      "[15]\tvalid_0's multi_error: 0.570687\tvalid_0's multi_logloss: 1.98586\n",
      "[16]\tvalid_0's multi_error: 0.568611\tvalid_0's multi_logloss: 1.97431\n",
      "[17]\tvalid_0's multi_error: 0.568611\tvalid_0's multi_logloss: 1.96376\n",
      "[18]\tvalid_0's multi_error: 0.567457\tvalid_0's multi_logloss: 1.95481\n",
      "[19]\tvalid_0's multi_error: 0.566765\tvalid_0's multi_logloss: 1.94617\n",
      "[20]\tvalid_0's multi_error: 0.566227\tvalid_0's multi_logloss: 1.93847\n",
      "[21]\tvalid_0's multi_error: 0.565573\tvalid_0's multi_logloss: 1.93124\n",
      "[22]\tvalid_0's multi_error: 0.56492\tvalid_0's multi_logloss: 1.92478\n",
      "[23]\tvalid_0's multi_error: 0.564074\tvalid_0's multi_logloss: 1.91902\n",
      "[24]\tvalid_0's multi_error: 0.563613\tvalid_0's multi_logloss: 1.91371\n",
      "[25]\tvalid_0's multi_error: 0.563728\tvalid_0's multi_logloss: 1.9095\n",
      "[26]\tvalid_0's multi_error: 0.562997\tvalid_0's multi_logloss: 1.9051\n",
      "[27]\tvalid_0's multi_error: 0.562651\tvalid_0's multi_logloss: 1.90154\n",
      "[28]\tvalid_0's multi_error: 0.562113\tvalid_0's multi_logloss: 1.89852\n",
      "[29]\tvalid_0's multi_error: 0.561998\tvalid_0's multi_logloss: 1.89495\n",
      "[30]\tvalid_0's multi_error: 0.561498\tvalid_0's multi_logloss: 1.89174\n",
      "[31]\tvalid_0's multi_error: 0.560998\tvalid_0's multi_logloss: 1.88901\n",
      "[32]\tvalid_0's multi_error: 0.561037\tvalid_0's multi_logloss: 1.8862\n",
      "[33]\tvalid_0's multi_error: 0.560844\tvalid_0's multi_logloss: 1.88401\n",
      "[34]\tvalid_0's multi_error: 0.561459\tvalid_0's multi_logloss: 1.88187\n",
      "[35]\tvalid_0's multi_error: 0.560498\tvalid_0's multi_logloss: 1.88021\n",
      "[36]\tvalid_0's multi_error: 0.559922\tvalid_0's multi_logloss: 1.87866\n",
      "[37]\tvalid_0's multi_error: 0.560152\tvalid_0's multi_logloss: 1.87699\n",
      "[38]\tvalid_0's multi_error: 0.560575\tvalid_0's multi_logloss: 1.87564\n",
      "[39]\tvalid_0's multi_error: 0.560037\tvalid_0's multi_logloss: 1.87427\n",
      "[40]\tvalid_0's multi_error: 0.559845\tvalid_0's multi_logloss: 1.87282\n",
      "[41]\tvalid_0's multi_error: 0.559768\tvalid_0's multi_logloss: 1.87167\n",
      "[42]\tvalid_0's multi_error: 0.559306\tvalid_0's multi_logloss: 1.87064\n",
      "[43]\tvalid_0's multi_error: 0.55996\tvalid_0's multi_logloss: 1.8695\n",
      "[44]\tvalid_0's multi_error: 0.559806\tvalid_0's multi_logloss: 1.86861\n",
      "[45]\tvalid_0's multi_error: 0.55996\tvalid_0's multi_logloss: 1.86813\n",
      "[46]\tvalid_0's multi_error: 0.558922\tvalid_0's multi_logloss: 1.86738\n",
      "[47]\tvalid_0's multi_error: 0.559037\tvalid_0's multi_logloss: 1.86664\n",
      "[48]\tvalid_0's multi_error: 0.559499\tvalid_0's multi_logloss: 1.86599\n",
      "[49]\tvalid_0's multi_error: 0.558768\tvalid_0's multi_logloss: 1.86552\n",
      "[50]\tvalid_0's multi_error: 0.558153\tvalid_0's multi_logloss: 1.86502\n",
      "[51]\tvalid_0's multi_error: 0.557768\tvalid_0's multi_logloss: 1.86458\n",
      "[52]\tvalid_0's multi_error: 0.558038\tvalid_0's multi_logloss: 1.86415\n",
      "[53]\tvalid_0's multi_error: 0.558422\tvalid_0's multi_logloss: 1.86384\n",
      "[54]\tvalid_0's multi_error: 0.55823\tvalid_0's multi_logloss: 1.86379\n",
      "[55]\tvalid_0's multi_error: 0.558768\tvalid_0's multi_logloss: 1.8637\n",
      "[56]\tvalid_0's multi_error: 0.557884\tvalid_0's multi_logloss: 1.86349\n",
      "[57]\tvalid_0's multi_error: 0.558038\tvalid_0's multi_logloss: 1.86325\n",
      "[58]\tvalid_0's multi_error: 0.55773\tvalid_0's multi_logloss: 1.86297\n",
      "[59]\tvalid_0's multi_error: 0.557692\tvalid_0's multi_logloss: 1.86304\n",
      "[60]\tvalid_0's multi_error: 0.558537\tvalid_0's multi_logloss: 1.86307\n",
      "[61]\tvalid_0's multi_error: 0.558653\tvalid_0's multi_logloss: 1.86306\n",
      "[62]\tvalid_0's multi_error: 0.558499\tvalid_0's multi_logloss: 1.86301\n",
      "[63]\tvalid_0's multi_error: 0.55823\tvalid_0's multi_logloss: 1.86335\n",
      "[64]\tvalid_0's multi_error: 0.559114\tvalid_0's multi_logloss: 1.86336\n",
      "[65]\tvalid_0's multi_error: 0.558268\tvalid_0's multi_logloss: 1.86324\n",
      "[66]\tvalid_0's multi_error: 0.557961\tvalid_0's multi_logloss: 1.86334\n",
      "[67]\tvalid_0's multi_error: 0.558576\tvalid_0's multi_logloss: 1.86338\n",
      "[68]\tvalid_0's multi_error: 0.557999\tvalid_0's multi_logloss: 1.86324\n",
      "[69]\tvalid_0's multi_error: 0.557999\tvalid_0's multi_logloss: 1.86336\n",
      "[70]\tvalid_0's multi_error: 0.557499\tvalid_0's multi_logloss: 1.86342\n",
      "[71]\tvalid_0's multi_error: 0.557692\tvalid_0's multi_logloss: 1.86344\n",
      "[72]\tvalid_0's multi_error: 0.558422\tvalid_0's multi_logloss: 1.86359\n",
      "[73]\tvalid_0's multi_error: 0.558153\tvalid_0's multi_logloss: 1.86404\n",
      "[74]\tvalid_0's multi_error: 0.558422\tvalid_0's multi_logloss: 1.86401\n",
      "[75]\tvalid_0's multi_error: 0.558576\tvalid_0's multi_logloss: 1.86404\n",
      "[76]\tvalid_0's multi_error: 0.558345\tvalid_0's multi_logloss: 1.86416\n",
      "[77]\tvalid_0's multi_error: 0.558268\tvalid_0's multi_logloss: 1.86422\n",
      "[78]\tvalid_0's multi_error: 0.558076\tvalid_0's multi_logloss: 1.86437\n",
      "[79]\tvalid_0's multi_error: 0.558038\tvalid_0's multi_logloss: 1.86483\n",
      "[80]\tvalid_0's multi_error: 0.557692\tvalid_0's multi_logloss: 1.86511\n",
      "正确率:  0.44230843169672035\n",
      "精确率:  0.41179993386909153\n",
      "评估:                    precision    recall  f1-score   support\n",
      "\n",
      "0,0,0,0,0,0,0,0,0       0.32      0.57      0.41      2819\n",
      "0,0,1,0,0,0,0,0,0       0.30      0.10      0.15       683\n",
      "0,1,0,0,0,0,0,0,0       0.26      0.14      0.18       655\n",
      "0,1,1,0,0,0,0,0,0       0.23      0.04      0.06       296\n",
      "1,0,0,0,0,0,0,0,0       0.22      0.15      0.18       782\n",
      "1,0,1,0,0,0,0,0,0       0.17      0.03      0.05       335\n",
      "1,1,0,0,0,0,0,0,0       0.21      0.07      0.11       424\n",
      "1,1,1,0,0,0,0,0,0       0.27      0.06      0.10       527\n",
      "1,1,1,0,0,1,0,0,0       0.35      0.18      0.24       474\n",
      "1,1,1,0,1,0,0,0,0       0.34      0.20      0.25       445\n",
      "1,1,1,0,1,1,0,0,0       0.26      0.13      0.17       333\n",
      "1,1,1,1,0,0,0,0,0       0.37      0.22      0.27       546\n",
      "1,1,1,1,0,1,0,0,0       0.27      0.12      0.16       336\n",
      "1,1,1,1,1,0,0,0,0       0.25      0.13      0.17       536\n",
      "1,1,1,1,1,1,0,0,0       0.18      0.03      0.04       355\n",
      "1,1,1,1,1,1,0,0,1       0.44      0.28      0.34       803\n",
      "1,1,1,1,1,1,0,1,0       0.43      0.27      0.33      1179\n",
      "1,1,1,1,1,1,0,1,1       0.38      0.28      0.32      1247\n",
      "1,1,1,1,1,1,1,0,0       0.41      0.32      0.36      1461\n",
      "1,1,1,1,1,1,1,0,1       0.36      0.28      0.32      1475\n",
      "1,1,1,1,1,1,1,1,0       0.51      0.71      0.60      4714\n",
      "1,1,1,1,1,1,1,1,1       0.55      0.71      0.62      5584\n",
      "\n",
      "         accuracy                           0.44     26009\n",
      "        macro avg       0.32      0.23      0.25     26009\n",
      "     weighted avg       0.41      0.44      0.41     26009\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_user = len(data_i)\n",
    "left = 0.9\n",
    "right = 1\n",
    "\n",
    "x_train = pd.concat([data_i[:int(n_user*left)],data_i[int(n_user*right):]])\n",
    "x_test = data_i[int(n_user*left):int(n_user*right)]\n",
    "# x_test = data_i[int(n_user*left):int(n_user*right)]\n",
    "y_train = pd.concat([y[:int(n_user*left)],y[int(n_user*right):]])\n",
    "y_test  = y[int(n_user*left):int(n_user*right)]\n",
    "# y_test  = y[int(n_user*left):int(n_user*right)]\n",
    "model.fit(x_train, y_train, eval_set =(x_test,y_test) ,eval_metric = 'multi_error')#,categorical_feature=categorical)#['item_class','user'])\n",
    "    # A={}\n",
    "# def unqiue_element(x):\n",
    "#     a = len(np.unique(x))\n",
    "#     A[x.name] = a\n",
    "# df[NUMERIC_COLS].apply(unqiue_element)\n",
    "# print(sorted ( A.items ( ) , key=lambda x: x[1], reverse=True))\n",
    "predictions = model.predict(x_test)\n",
    "print( '正确率: ',model.score(x_test, y_test))\n",
    "print( '精确率: ',precision_score(y_test,predictions,average = 'weighted'))\n",
    "labels = ['0,0,0,0,0,0,0,0,0','0,0,1,0,0,0,0,0,0','0,1,0,0,0,0,0,0,0','0,1,1,0,0,0,0,0,0','1,0,0,0,0,0,0,0,0','1,0,1,0,0,0,0,0,0','1,1,0,0,0,0,0,0,0','1,1,1,0,0,0,0,0,0','1,1,1,0,0,1,0,0,0','1,1,1,0,1,0,0,0,0','1,1,1,0,1,1,0,0,0','1,1,1,1,0,0,0,0,0','1,1,1,1,0,1,0,0,0','1,1,1,1,1,0,0,0,0','1,1,1,1,1,1,0,0,0','1,1,1,1,1,1,0,0,1','1,1,1,1,1,1,0,1,0','1,1,1,1,1,1,0,1,1','1,1,1,1,1,1,1,0,0','1,1,1,1,1,1,1,0,1','1,1,1,1,1,1,1,1,0','1,1,1,1,1,1,1,1,1']\n",
    "# labels = [1,2,3,4,5,6,7]\n",
    "print('评估:',classification_report(y_test,predictions,target_names=labels))\n",
    "\n",
    "\n",
    "\n",
    "# from sklearn.model_selection import StratifiedKFold,KFold\n",
    "# from sklearn.metrics import precision_score,recall_score,roc_auc_score,classification_report\n",
    "# # kf = StratifiedKFold(n_splits = 5)#, shuffle = True, random_state = 40)\n",
    "# kf = KFold(n_splits = 10, shuffle = True, random_state = 0)\n",
    "# # y_pred = np.zeros(len(x_test))\n",
    "\n",
    "# for fold,(train_index,val_index) in enumerate(kf.split(data_i,y)):\n",
    "# #     print(train_index,'\\n',val_index)\n",
    "#     x_train,x_test = data_i.iloc[train_index],data_i.iloc[val_index]\n",
    "# #     Y_train = Y_train.str.split(',')\n",
    "#     y_train,y_test = y.iloc[train_index],y.iloc[val_index]\n",
    "#     model.fit(x_train, y_train,categorical_feature=categorical_feature)# ,categorical_feature=['item_class','user'])\n",
    "#         # A={}\n",
    "#     # def unqiue_element(x):\n",
    "#     #     a = len(np.unique(x))\n",
    "#     #     A[x.name] = a\n",
    "#     # df[NUMERIC_COLS].apply(unqiue_element)\n",
    "#     # print(sorted ( A.items ( ) , key=lambda x: x[1], reverse=True))\n",
    "#     predictions = model.predict(x_test)\n",
    "#     print( '正确率: ',model.score(x_test, y_test))\n",
    "#     print( '精确率: ',precision_score(y_test,predictions,average = 'weighted'))\n",
    "#     labels = ['0,0,0,0,0,0,0,0,0','0,0,1,0,0,0,0,0,0','0,1,0,0,0,0,0,0,0','0,1,1,0,0,0,0,0,0','1,0,0,0,0,0,0,0,0','1,0,1,0,0,0,0,0,0','1,1,0,0,0,0,0,0,0','1,1,1,0,0,0,0,0,0','1,1,1,0,0,1,0,0,0','1,1,1,0,1,0,0,0,0','1,1,1,0,1,1,0,0,0','1,1,1,1,0,0,0,0,0','1,1,1,1,0,1,0,0,0','1,1,1,1,1,0,0,0,0','1,1,1,1,1,1,0,0,0','1,1,1,1,1,1,0,0,1','1,1,1,1,1,1,0,1,0','1,1,1,1,1,1,0,1,1','1,1,1,1,1,1,1,0,0','1,1,1,1,1,1,1,0,1','1,1,1,1,1,1,1,1,0','1,1,1,1,1,1,1,1,1']\n",
    "#     # labels = [1,2,3,4,5,6,7]\n",
    "#     print('评估:',classification_report(y_test,predictions,target_names=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical = []\n",
    "# for i in range(18):\n",
    "#     if i == 0:\n",
    "#         categorical.append('item_class')\n",
    "#         continue\n",
    "#     categorical.append('item_class.'+str(i))\n",
    "\n",
    "# for i in [0,2,3,6,7,8]:\n",
    "#     if i == 0:\n",
    "#         categorical.append('user')\n",
    "#         continue\n",
    "#     categorical.append('user.'+str(i))\n",
    "\n",
    "# weights = {'0,0,0,0,0,0,0,0,0':1,'0,0,1,0,0,0,0,0,0':2,'0,1,0,0,0,0,0,0,0':1.8,'0,1,1,0,0,0,0,0,0':3.6,\n",
    "#            '1,0,0,0,0,0,0,0,0':1.5,'1,0,1,0,0,0,0,0,0':3,'1,1,0,0,0,0,0,0,0':2.2,'1,1,1,0,0,0,0,0,0':2.9,\n",
    "#            '1,1,1,0,0,1,0,0,0':1.9,'1,1,1,0,1,0,0,0,0':2,'1,1,1,0,1,1,0,0,0':2,'1,1,1,1,0,0,0,0,0':1.8,\n",
    "#            '1,1,1,1,0,1,0,0,0':2,'1,1,1,1,1,0,0,0,0':1.6,'1,1,1,1,1,1,0,0,0':3,'1,1,1,1,1,1,0,0,1':1.5,\n",
    "#            '1,1,1,1,1,1,0,1,0':1.2,'1,1,1,1,1,1,0,1,1':1.05,'1,1,1,1,1,1,1,0,0':1.05,'1,1,1,1,1,1,1,0,1':1,\n",
    "#            '1,1,1,1,1,1,1,1,0':0.9,'1,1,1,1,1,1,1,1,1':0.9}\n",
    "\n",
    "# weights = {'0,0,0,0,0,0,0,0,0':0.8,'0,0,1,0,0,0,0,0,0':1,'0,1,0,0,0,0,0,0,0':1,'0,1,1,0,0,0,0,0,0':1.2,\n",
    "#            '1,0,0,0,0,0,0,0,0':1,'1,0,1,0,0,0,0,0,0':1.2,'1,1,0,0,0,0,0,0,0':1,'1,1,1,0,0,0,0,0,0':1.2,\n",
    "#            '1,1,1,0,0,1,0,0,0':1,'1,1,1,0,1,0,0,0,0':1,'1,1,1,0,1,1,0,0,0':1,'1,1,1,1,0,0,0,0,0':1,\n",
    "#            '1,1,1,1,0,1,0,0,0':1,'1,1,1,1,1,0,0,0,0':1,'1,1,1,1,1,1,0,0,0':1.2,'1,1,1,1,1,1,0,0,1':1,\n",
    "#            '1,1,1,1,1,1,0,1,0':1,'1,1,1,1,1,1,0,1,1':1,'1,1,1,1,1,1,1,0,0':1.,'1,1,1,1,1,1,1,0,1':1,\n",
    "#            '1,1,1,1,1,1,1,1,0':0.8,'1,1,1,1,1,1,1,1,1':0.8}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import lightgbm\n",
    "# import xgboost\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from mlxtend.classifier import StackingCVClassifier\n",
    "# from sklearn import metrics\n",
    "# # 基分类器3个：DecisionTreeClassifier， GradientBoostingClassifier，RandomForestClassifier\n",
    "# # 目标分类器：LogisticRegression\n",
    "# # 使用3折交叉验证\n",
    "# basemodel1 = lightgbm.LGBMClassifier(boosting_type='gbdt', num_leaves=256,reg_alpha=0.0,reg_lambda=1,\n",
    "#                                      max_depth=8, n_estimators=80,objective='multiclassova' ,num_class = 22,\n",
    "#                                      learning_rate=0.08,random_state=20,n_jobs=4)\n",
    "# basemodel2 = xgboost.XGBClassifier(reg_alpha=0.0,reg_lambda=1,max_depth=6, n_estimators=80,\n",
    "#                                    objective='multi:softmax' ,num_class = 22,learning_rate=0.08,random_state=20)\n",
    "# basemodel3 = RandomForestClassifier(max_features=None,random_state=20, n_estimators=80,criterion='gini' ,max_depth=10,verbose=0,\n",
    "#                                     warm_start=False,class_weight=None)\n",
    "\n",
    "# lr = LogisticRegression()\n",
    "# sclf = StackingCVClassifier(classifiers=[basemodel1, basemodel2, basemodel3], meta_classifier=lr,\n",
    "#                                    use_probas=True, verbose=2, cv=5)\n",
    "\n",
    "# # basemodel1 = tree.DecisionTreeClassifier()\n",
    "# # basemodel2 = GradientBoostingClassifier()\n",
    "# # basemodel3 = RandomForestClassifier()\n",
    "# # lr = LogisticRegression()\n",
    "# # sclf = StackingCVClassifier(classifiers=[basemodel1, basemodel2, basemodel3], meta_classifier=lr,\n",
    "# #                                    use_probas=True, verbose=2, cv=3)\n",
    "# sclf.fit(x_train, y_train)\n",
    "# sclf_predict = sclf.predict(x_test)\n",
    "# sclf_predict_proba = sclf.predict_proba(x_test)[:,1]\n",
    "# print('评估:',classification_report(y_test,sclf_predict,target_names=labels))\n",
    "# print('score',sclf.score(y_test, sclf_predict, sclf_predict_proba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>user.1</td>\n",
       "      <td>8922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>user.9</td>\n",
       "      <td>8730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>scores.8</td>\n",
       "      <td>8379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>scores.7</td>\n",
       "      <td>7858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>scores.6</td>\n",
       "      <td>7857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>probability.7</td>\n",
       "      <td>7748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>probability.5</td>\n",
       "      <td>7746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>probability.6</td>\n",
       "      <td>7647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>rare.5</td>\n",
       "      <td>7283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>probability.8</td>\n",
       "      <td>7116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>scores.2</td>\n",
       "      <td>7092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>scores</td>\n",
       "      <td>7016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>user.4</td>\n",
       "      <td>6988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>rare.4</td>\n",
       "      <td>6963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>scores.5</td>\n",
       "      <td>6961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>scores.1</td>\n",
       "      <td>6943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>scores.4</td>\n",
       "      <td>6933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>scores.3</td>\n",
       "      <td>6755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>probability.4</td>\n",
       "      <td>6647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>probability.3</td>\n",
       "      <td>6603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>rare.3</td>\n",
       "      <td>6537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>group_scores</td>\n",
       "      <td>6494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>group_scores.1</td>\n",
       "      <td>6311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>rare.8</td>\n",
       "      <td>6289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>rare.6</td>\n",
       "      <td>5817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>rare.7</td>\n",
       "      <td>5737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>price.5</td>\n",
       "      <td>5599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>price.8</td>\n",
       "      <td>5321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>rare.2</td>\n",
       "      <td>5245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>rare</td>\n",
       "      <td>5141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>rare.1</td>\n",
       "      <td>5082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>price.6</td>\n",
       "      <td>5074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>price.4</td>\n",
       "      <td>5072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>price.3</td>\n",
       "      <td>5062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>price.7</td>\n",
       "      <td>5035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>probability.2</td>\n",
       "      <td>4536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>probability</td>\n",
       "      <td>4478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>probability.1</td>\n",
       "      <td>4447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>user.5</td>\n",
       "      <td>4434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>price.1</td>\n",
       "      <td>4253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>price.2</td>\n",
       "      <td>4166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>price</td>\n",
       "      <td>4030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>interval</td>\n",
       "      <td>3865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>user.2</td>\n",
       "      <td>3809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>user.3</td>\n",
       "      <td>3692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>user.7</td>\n",
       "      <td>2559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>item_class.15</td>\n",
       "      <td>2171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>item_class.13</td>\n",
       "      <td>2135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>item_class.17</td>\n",
       "      <td>2117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>item_class.11</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            column  importance\n",
       "57          user.1        8922\n",
       "65          user.9        8730\n",
       "8         scores.8        8379\n",
       "7         scores.7        7858\n",
       "6         scores.6        7857\n",
       "51   probability.7        7748\n",
       "43   probability.5        7746\n",
       "47   probability.6        7647\n",
       "42          rare.5        7283\n",
       "55   probability.8        7116\n",
       "2         scores.2        7092\n",
       "0           scores        7016\n",
       "60          user.4        6988\n",
       "38          rare.4        6963\n",
       "5         scores.5        6961\n",
       "1         scores.1        6943\n",
       "4         scores.4        6933\n",
       "3         scores.3        6755\n",
       "39   probability.4        6647\n",
       "35   probability.3        6603\n",
       "34          rare.3        6537\n",
       "9     group_scores        6494\n",
       "10  group_scores.1        6311\n",
       "54          rare.8        6289\n",
       "46          rare.6        5817\n",
       "50          rare.7        5737\n",
       "72         price.5        5599\n",
       "75         price.8        5321\n",
       "30          rare.2        5245\n",
       "22            rare        5141\n",
       "26          rare.1        5082\n",
       "73         price.6        5074\n",
       "71         price.4        5072\n",
       "70         price.3        5062\n",
       "74         price.7        5035\n",
       "31   probability.2        4536\n",
       "23     probability        4478\n",
       "27   probability.1        4447\n",
       "61          user.5        4434\n",
       "68         price.1        4253\n",
       "69         price.2        4166\n",
       "67           price        4030\n",
       "66        interval        3865\n",
       "58          user.2        3809\n",
       "59          user.3        3692\n",
       "63          user.7        2559\n",
       "49   item_class.15        2171\n",
       "45   item_class.13        2135\n",
       "53   item_class.17        2117\n",
       "41   item_class.11        1999"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'column':data_i.columns.tolist(),'importance':model.feature_importances_}).sort_values(by='importance' , ascending=False)[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1 1 1 1 1 1 1 1 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1 1 1 1 1 1 1 1 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1 1 1 0 0 1 0 0 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1 1 1 1 1 1 1 1 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1 1 1 1 1 1 0 1 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206249</th>\n",
       "      <td>206250</td>\n",
       "      <td>1 1 1 1 1 1 1 1 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206250</th>\n",
       "      <td>206251</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206251</th>\n",
       "      <td>206252</td>\n",
       "      <td>1 1 1 1 1 1 1 0 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206252</th>\n",
       "      <td>206253</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206253</th>\n",
       "      <td>206254</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>206254 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id           category\n",
       "0            1  1 1 1 1 1 1 1 1 1\n",
       "1            2  1 1 1 1 1 1 1 1 1\n",
       "2            3  1 1 1 0 0 1 0 0 0\n",
       "3            4  1 1 1 1 1 1 1 1 0\n",
       "4            5  1 1 1 1 1 1 0 1 1\n",
       "...        ...                ...\n",
       "206249  206250  1 1 1 1 1 1 1 1 1\n",
       "206250  206251  0 0 0 0 0 0 0 0 0\n",
       "206251  206252  1 1 1 1 1 1 1 0 1\n",
       "206252  206253  0 0 0 0 0 0 0 0 0\n",
       "206253  206254  0 0 0 0 0 0 0 0 0\n",
       "\n",
       "[206254 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid = model.predict(x_valid)\n",
    "# y_valid = sclf.predict(x_valid)\n",
    "aa = y_valid.tolist()\n",
    "for n,i in enumerate(aa):\n",
    "    i = i.split(',')\n",
    "    aa[n] = ' '.join(i)\n",
    "n_user = data_i_v.shape[0]\n",
    "i = pd.DataFrame([i for i in range(1,n_user+1)],columns = ['id'])\n",
    "aa = pd.DataFrame(aa,columns = ['category'])\n",
    "res = pd.concat([i,aa],axis = 1)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.to_csv('./datasets/res.csv',sep = ',',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rob",
   "language": "python",
   "name": "rob"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
